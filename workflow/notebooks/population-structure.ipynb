{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01954f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "\n",
    "def plot_pca(pca_df, colour_column, cohort_columns, dataset,  x='PC1',y='PC2',z='PC3', color_mapping=None, height=500, width=750):\n",
    "    fig= px.scatter_3d(\n",
    "        pca_df, \n",
    "        x=x, \n",
    "        y=y,\n",
    "        z=z, \n",
    "        title=f\"PCA {dataset} | PC1 vs PC2 vs PC3 coloured by {colour_column}\",\n",
    "        color=colour_column, \n",
    "        hover_data=cohort_columns + ['sample_id'],\n",
    "        color_discrete_map=color_mapping[colour_column], \n",
    "        template='simple_white',\n",
    "        height=height,\n",
    "        width=width\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6302ed5",
   "metadata": {
    "tags": [
     "parameters",
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = 'ag-vampir-002'\n",
    "vcf_path = f\"../../results/vcfs/amplicons/{dataset}.annot.vcf\"\n",
    "metadata_path = \"../../results/config/metadata.qcpass.tsv\"\n",
    "cohort_cols = 'location,taxon'\n",
    "wkdir = \"../../\"\n",
    "platform = 'illumina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72254713",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(wkdir, 'workflow'))\n",
    "import ampseekertools as amp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696938a0",
   "metadata": {},
   "source": [
    "## Population structure\n",
    "\n",
    "In this notebook, we run a principal components analysis and build a neighbour joining tree on the amplicon sequencing variant data. For the PCA, we will plot PC1 v PC2 and PC3 v PC4, and the variance explained by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae6392",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "cohort_cols = cohort_cols.split(\",\")\n",
    "cohort_col = cohort_cols[0]\n",
    "\n",
    "metadata = pd.read_csv(metadata_path, sep=\"\\t\")\n",
    "\n",
    "import json\n",
    "with open(f\"{wkdir}/results/config/metadata_colours.json\", 'r') as f:\n",
    "    color_mapping = json.load(f)\n",
    "\n",
    "geno, pos, contig, metadata, ref, alt, ann = amp.load_vcf(vcf_path, metadata, platform=platform)\n",
    "df_pca, model = amp.pca(geno=geno, metadata=metadata, n_components=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b018edf",
   "metadata": {},
   "source": [
    "#### Variance explained\n",
    "\n",
    "The variance explained shows the proportion of total variance in the dataset that is captured by each principal component. Higher values indicate more informative components. As a general rule of thumb, when the variance explained for each PC begins to flatten out, that is when the PCs are no longer informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a0d44",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig = px.bar(model.explained_variance_ratio_ , labels={\n",
    "                     \"value\": \"Variance Explained\",\n",
    "                     \"index\": \"Principal Component\",\n",
    "                 }, template='simple_white', height=250, width=600)\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b98cf",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "Principal Component Analysis (PCA) is a dimensionality reduction technique that transforms high-dimensional genetic data into a smaller set of uncorrelated variables (Reich et al., 2008). It helps visualize population structure and genetic relationships between samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e807c",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "for coh in cohort_cols:\n",
    "    fig1 = plot_pca(df_pca, x='PC1',y='PC2',z='PC3', colour_column=coh, cohort_columns=cohort_cols, dataset=dataset, color_mapping=color_mapping)\n",
    "    fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bbe3f6",
   "metadata": {},
   "source": [
    "## NJT\n",
    "\n",
    "Neighbor-Joining Tree (NJT) is a clustering method that reconstructs evolutionary relationships between samples based on genetic distances (Saitou & Nei, 1987). It creates a tree where genetically similar samples cluster together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0977f1",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import anjl\n",
    "from scipy.spatial.distance import squareform\n",
    "import allel\n",
    "\n",
    "# find seg sites and remove highly missing sites\n",
    "ac = geno.count_alleles()\n",
    "seg = ac.is_segregating()\n",
    "gn_seg = geno.compress(seg, axis=0)\n",
    "missing_mask = gn_seg.is_missing().sum(axis=1) > gn_seg.shape[1] * 0.05\n",
    "gn_seg = gn_seg.compress(~missing_mask, axis=0)\n",
    "\n",
    "ac = allel.GenotypeArray(gn_seg).to_allele_counts(max_allele=3)\n",
    "X = np.ascontiguousarray(np.swapaxes(ac.values, 0, 1))\n",
    "\n",
    "dists = amp.multiallelic_diplotype_pdist(X, metric=amp.multiallelic_diplotype_mean_cityblock)\n",
    "dists = squareform(dists)\n",
    "df_samples = metadata.set_index('sample_id')\n",
    "df = df_samples[[cohort_col]]\n",
    "\n",
    "df_dist_matrix = pd.DataFrame(dists, index=df_samples.index.to_list(), columns=df_samples.index.to_list())\n",
    "# pivot long \n",
    "df_dists = df_dist_matrix.stack().reset_index().set_axis('sample_id_x sample_id_y distance'.split(), axis=1)\n",
    "# merge with metadata\n",
    "df_dists = df_dists.merge(df, left_on='sample_id_x', right_index=True).merge(df, left_on='sample_id_y', right_index=True, suffixes=('_x', '_y'))\n",
    "# remove self comparisons\n",
    "df_dists = df_dists[df_dists['sample_id_x'] != df_dists['sample_id_y']]\n",
    "# dedup\n",
    "df_dists = df_dists.assign(dedup=np.array([''.join(sorted([a,b])) for a,b in zip(df_dists.sample_id_x, df_dists.sample_id_y)]).astype(str))\n",
    "df_dists = df_dists.sort_values('sample_id_x').drop_duplicates('dedup').drop('dedup', axis=1)\n",
    "# normalise distances\n",
    "df_dists[cohort_col] = df_dists[f'{cohort_col}_x'] + \" | \" + df_dists[f'{cohort_col}_y']\n",
    "df_dists = df_dists.drop([f'{cohort_col}_x', f'{cohort_col}_y'], axis=1)\n",
    "df_grp_dists = df_dists.groupby(cohort_col).agg({'distance': 'mean'}).sort_values('distance').rename(columns={'distance': 'mean_distance'}).reset_index()\n",
    "df_dists = df_dists.merge(df_grp_dists, on=cohort_col).assign(normalised_dist=lambda x: x.distance - x.mean_distance).sort_values('normalised_dist')\n",
    "\n",
    "# get the 500 most distant samples and exclude highly irregular ones \n",
    "far_samples = df_dists.sort_values('normalised_dist', ascending=False)[:int(df_dists.shape[0] * 0.005)][['sample_id_x', 'sample_id_y']].values.flatten()\n",
    "far_samples, far_counts = np.unique(far_samples, return_counts=True)\n",
    "exclude_outliers = far_samples[far_counts > int(df_samples.shape[0] * 0.1)]\n",
    "print(f\"excluding extreme outliers from NJT\", exclude_outliers)\n",
    "\n",
    "dists = df_dist_matrix.drop(exclude_outliers, axis=0).drop(exclude_outliers, axis=1).values\n",
    "leaf_data = df_samples.query(\"sample_id not in @exclude_outliers\").reset_index()\n",
    "#leaf_data = leaf_data.merge(df_kdr_origins[['sample_id', 'kdr_origin']], on='sample_id', how='left')\n",
    "\n",
    "Z = anjl.dynamic_nj(dists)\n",
    "\n",
    "for col in cohort_cols:\n",
    "    fig = anjl.plot(\n",
    "        Z,\n",
    "        leaf_data=leaf_data,\n",
    "        color=col,\n",
    "        hover_name=\"sample_id\",\n",
    "        hover_data=cohort_cols,# + ['kdr_origin'],  \n",
    "        color_discrete_map=color_mapping[col],\n",
    "        marker_size=8\n",
    "    )\n",
    "    fig.write_image(f\"{wkdir}/results/njt_{col}.png\", scale=2)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac9a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235001b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82577766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
