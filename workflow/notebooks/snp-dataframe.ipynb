{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdcabe6",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import allel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def vcf_to_excel(vcf_path, excel_path, convert_genotypes=False, split_multiallelic=False):\n",
    "    # Read VCF and create a dictionary\n",
    "    vcf_df = vcf_to_df(vcf_path)\n",
    "    samples = vcf_df.columns[6:]\n",
    "\n",
    "    # Create a DataFrame for variants\n",
    "    if split_multiallelic:\n",
    "        vcf_df = split_rows_with_multiple_alleles(vcf_df, samples)\n",
    "\n",
    "    # Convert genotypes to 0/1/2\n",
    "    if convert_genotypes:\n",
    "        vcf_df = convert_genotype_to_alt_allele_count(vcf_df, samples)\n",
    "    \n",
    "    if excel_path:\n",
    "        # Write to Excel\n",
    "        vcf_df.to_excel(excel_path, index=False)\n",
    "\n",
    "def vcf_to_df(vcf_path, seg=True):\n",
    "    \n",
    "    vcf_dict = allel.read_vcf(vcf_path, fields='*')\n",
    "    contig = vcf_dict['variants/CHROM'] \n",
    "    pos = vcf_dict['variants/POS']\n",
    "    filter_pass = vcf_dict['variants/FILTER_PASS']\n",
    "    ref = vcf_dict['variants/REF']\n",
    "    alt = np.apply_along_axis(lambda x: ','.join(x[x != '']), 1, vcf_dict['variants/ALT'])\n",
    "    ann = vcf_dict['variants/ANN']\n",
    "\n",
    "    geno = allel.GenotypeArray(vcf_dict['calldata/GT'])\n",
    "\n",
    "    if seg:\n",
    "        ac = geno.count_alleles(max_allele=3)\n",
    "        mask_seg = ac.is_segregating()\n",
    "        geno = geno.compress(mask_seg, axis=0)\n",
    "        contig = contig[mask_seg]\n",
    "        pos = pos[mask_seg]\n",
    "        filter_pass = filter_pass[mask_seg]\n",
    "        ref = ref[mask_seg]\n",
    "        alt = alt[mask_seg]\n",
    "        ann = ann[mask_seg]\n",
    "\n",
    "    ### make pd dataframe version of vcf\n",
    "    vcf_df = pd.DataFrame({'CHROM': contig, 'POS': pos, 'FILTER_PASS': filter_pass, 'REF': ref, 'ALT': alt, 'ANN': ann})\n",
    "    # make pd dataframe version of genotypes\n",
    "    geno_df = pd.DataFrame(geno.to_gt().astype(str), columns=vcf_dict['samples'])\n",
    "    vcf = pd.concat([vcf_df, geno_df], axis=1)\n",
    "    return vcf\n",
    "\n",
    "def split_rows_with_multiple_alleles(df, samples):\n",
    "    # Create an empty list to store the new rows\n",
    "    new_rows = []\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        alt_alleles = row['ALT'].split(',')\n",
    "        # Check if there are multiple alleles in the ALT field\n",
    "        if len(alt_alleles) > 1:\n",
    "            for allele_num, allele in enumerate(alt_alleles):\n",
    "                # Create a new row for each allele\n",
    "                new_row = row.copy()\n",
    "                new_row['ALT'] = allele\n",
    "                # Update genotype fields\n",
    "                for col in samples:\n",
    "                    genotype = row[col]\n",
    "                    # Split the genotype and process it\n",
    "                    if genotype != './.':\n",
    "                        gt_alleles = genotype.split('/')\n",
    "                        new_gt = ['0' if (int(gt) != allele_num + 1 and gt != '0') else gt for gt in gt_alleles]\n",
    "                        new_row[col] = '/'.join(new_gt)\n",
    "                new_rows.append(new_row)\n",
    "        else:\n",
    "            new_rows.append(row)\n",
    "    \n",
    "    # Create a new DataFrame from the new rows\n",
    "    new_df = pd.DataFrame(new_rows).reset_index(drop=True)\n",
    "    return new_df\n",
    "\n",
    "def convert_genotype_to_alt_allele_count(df, samples):\n",
    "    nalt_df = df.copy()\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        # Update genotype fields\n",
    "        for col in samples:\n",
    "                genotype = row[col]\n",
    "                if genotype != './.':\n",
    "                    # Split the genotype and count non-zero alleles\n",
    "                    alleles = genotype.split('/')\n",
    "                    alt_allele_count = sum([1 for allele in alleles if allele != '0'])\n",
    "                    nalt_df.at[index, col] = alt_allele_count\n",
    "                else:\n",
    "                    nalt_df.at[index, col] = np.nan\n",
    "\n",
    "    return nalt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab3057",
   "metadata": {
    "tags": [
     "parameters",
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"nomads16\"\n",
    "wkdir = \"../..\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612c170f",
   "metadata": {},
   "source": [
    "# SNP data\n",
    "\n",
    "In this notebook, we display the variant calling and annotation results as a pandas dataframe and save it as an excel spreadsheet for the user to explore or analyse further. If the DataFrame is too large to display, please use the .xlsx file. \n",
    "\n",
    "#### Target SNP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983bb2c8",
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "vcf_df = vcf_to_excel(\n",
    "    vcf_path=f\"{wkdir}/results/vcfs/targets/{dataset}.annot.vcf\",\n",
    "    excel_path=f\"{wkdir}/results/vcfs/targets/{dataset}-snps.xlsx\",\n",
    "    convert_genotypes=True,\n",
    "    split_multiallelic=True,\n",
    ")\n",
    "pd.set_option(\"display.max_rows\", 1000, \"display.max_columns\", 1000)\n",
    "vcf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff0828c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f41f95",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(f'<a href=\"{wkdir}/results/vcfs/targets/{dataset}-snps.xlsx\">Target SNP data (.xlsx)</a>'))\n",
    "display(Markdown(f'<a href=\"{wkdir}/results/vcfs/targets/{dataset}.annot.vcf\">Target SNP data (.vcf)</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f4ab3",
   "metadata": {},
   "source": [
    "#### Whole-amplicon SNP data\n",
    "\n",
    "For times sake, we do not write out whole-amplicon .xlsx by default - it is slow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1735dc71",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "vcf_df = vcf_to_excel(\n",
    "    vcf_path=f\"{wkdir}/results/vcfs/amplicons/{dataset}.annot.vcf\",\n",
    "    excel_path=f\"{wkdir}/results/vcfs/amplicons/{dataset}-snps.xlsx\",\n",
    "    convert_genotypes=True,\n",
    "    split_multiallelic=True\n",
    ")\n",
    "vcf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c4f01",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f18b21",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "display(Markdown(f'<a href=\"{wkdir}/results/vcfs/amplicons/{dataset}-snps.xlsx\">Whole amplicon SNP data (.xlsx)</a>'))\n",
    "display(Markdown(f'<a href=\"{wkdir}/results/vcfs/amplicons/{dataset}.annot.vcf\">Whole amplicon SNP data (.vcf)</a>'))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
