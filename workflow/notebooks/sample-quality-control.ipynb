{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b99e40c",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import allel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308ef38",
   "metadata": {
    "tags": [
     "remove-input",
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "metadata_path = '../../config/metadata.tsv'\n",
    "bed_targets_path = \"../../config/ag-vampir.bed\"\n",
    "dataset = 'ag-vampir-002'\n",
    "vcf_path = f\"../../results/vcfs/targets/{dataset}.annot.vcf\"\n",
    "wkdir = \"../..\"\n",
    "cohort_cols = 'location'\n",
    "panel = 'ag-vampir'\n",
    "platform = 'illumina'\n",
    "\n",
    "sample_total_read_threshold = 250\n",
    "amplicon_total_read_threshold = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b002ad5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(wkdir, 'workflow'))\n",
    "import ampseekertools as amp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a842a6",
   "metadata": {},
   "source": [
    "# Sample quality control \n",
    "\n",
    "In this notebook, we perform quality control on samples, removing samples with very low depth or elevated heterozygosity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1552f7",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "cohort_col = cohort_cols.split(',')[0]\n",
    "\n",
    "metadata = pd.read_csv(metadata_path, sep=\"\\t\")\n",
    "\n",
    "import json\n",
    "with open(f\"{wkdir}/results/config/metadata_colours.json\", 'r') as f:\n",
    "    color_mapping = json.load(f)\n",
    "\n",
    "panel_metadata = pd.read_csv(\n",
    "    bed_targets_path, \n",
    "    sep=\"\\t\", \n",
    "    header=None, \n",
    "    names=['contig', 'start', 'end', 'amplicon', 'mutation', 'ref', 'alt']\n",
    ")\n",
    "\n",
    "geno, pos, contigs, metadata, ref, alts, ann = amp.load_vcf(vcf_path, metadata, platform=platform)\n",
    "samples = metadata['sample_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48786245",
   "metadata": {},
   "source": [
    "## Coverage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815337c7",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "target_covs = []\n",
    "x_ratios = []\n",
    "for sample in metadata.sample_id:\n",
    "    target_cov = pd.read_csv(f\"{wkdir}/results/coverage/{sample}.regions.bed.gz\", sep=\"\\t\", header=None, names=['contig', 'start', 'end', 'amplicon', 'depth', 'sample_id'])\n",
    "    target_cov = target_cov.assign(sample_id=sample)\n",
    "    target_covs.append(target_cov)\n",
    "    \n",
    "    # x-autosome ratio\n",
    "    if panel == 'ag-vampir':\n",
    "        contig_depth = target_cov.groupby('contig').agg({'depth':'sum'})\n",
    "        x_ratios.append((contig_depth.loc[['2L', '2R', '3L', '3R']].sum() / contig_depth.loc['X']).iloc[0])\n",
    "    \n",
    "target_cov_df = pd.concat(target_covs, axis=0)\n",
    "target_cov_df = target_cov_df.merge(panel_metadata, how='left', on=['contig', 'start', 'end', 'amplicon'])\n",
    "\n",
    "sample_cov_df = target_cov_df.groupby('sample_id').agg({'depth':'sum'}).reset_index()\n",
    "\n",
    "fig = px.histogram(sample_cov_df, x='depth', nbins=500, template='simple_white', \n",
    "                   width=800, height=300, title='Histogram of total read counts per sample')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b833b421",
   "metadata": {},
   "source": [
    "How many samples fall below the threshold for total reads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a945c4",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "exclude_samples_depth = sample_cov_df.query(\"depth < @sample_total_read_threshold\")['sample_id']\n",
    "print(f\"Removing {len(exclude_samples_depth)} samples due to low total depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d5213",
   "metadata": {},
   "source": [
    "#### Total reads per target SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d9efa",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "amplicon_cov_df = target_cov_df.groupby('mutation').agg({'depth':'sum'}).reset_index()\n",
    "\n",
    "fig = px.histogram(amplicon_cov_df, x='depth', nbins=200, color='mutation', template='simple_white', \n",
    "                   width=800, height=350, \n",
    "                   title='Histogram of total read counts per SNP target')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7079202",
   "metadata": {},
   "source": [
    "Which target SNPs have lower total depth than the amplicon threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738ab8d",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "exclude_targets_depth = amplicon_cov_df.query(\"depth < 100\")['mutation']\n",
    "print(f\"Removing {len(exclude_targets_depth)} target SNPs due to low total depth\")\n",
    "\n",
    "pd.DataFrame(exclude_targets_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9371586",
   "metadata": {},
   "source": [
    "### Number of missing calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6824f5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "min_missing_calls = 60 #int(panel_metadata.shape[0] / 2)\n",
    "\n",
    "exclude_samples_missing_calls = samples[(geno.is_missing().sum(axis=0) > min_missing_calls)]\n",
    "print(f\"{len(exclude_samples_missing_calls)} samples have more than {min_missing_calls} missing calls overall out of all possible target SNPs\")\n",
    "\n",
    "a = exclude_samples_missing_calls\n",
    "b = exclude_samples_depth\n",
    "\n",
    "# how many samples are shared between the exclude missing calls and depth lists \n",
    "overlap = len(set(a) & set(b))\n",
    "\n",
    "print(f\"{overlap}/{len(exclude_samples_missing_calls)} of these are also present in the low depth samples to be excluded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5c9601",
   "metadata": {},
   "source": [
    "### Autosome / Sex chromosome coverage ratios (ag-vampir only)\n",
    "\n",
    "Females will have a lower ratio of autosomes:x, and males will have a higher ratio. Its not clear whether we can use this yet to sex samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84386ac",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if panel == 'ag-vampir':\n",
    "    x_ratio_df = pd.DataFrame({'sample_id':metadata.sample_id, 'x_ratio':x_ratios})\n",
    "    x_ratio_df = x_ratio_df.query(\"sample_id not in @exclude_samples_depth\")\n",
    "\n",
    "    fig = px.histogram(x_ratio_df, x='x_ratio', color='sample_id', template='simple_white', nbins=1000, width=800, height=300)\n",
    "    fig.update_xaxes(range=(0,20), title=dict(text='Autosome / X depth ratio'))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a5b5a",
   "metadata": {},
   "source": [
    "### Sample heterozygosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703550f9",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def calc_heterozygosity(gt, gt_samples):   \n",
    "    het_per_sample = [np.nanmean(allel.heterozygosity_observed(gt[:, [i], :])) for i in range(gt.shape[1])]\n",
    "    het_df = pd.DataFrame({'sample_id':gt_samples, 'heterozygosity':het_per_sample})\n",
    "    return het_df.set_index(\"sample_id\")\n",
    "\n",
    "het_df = calc_heterozygosity(gt=geno, gt_samples=samples).reset_index()\n",
    "het_df = het_df.merge(metadata)\n",
    "\n",
    "fig = px.bar(\n",
    "    het_df, \n",
    "    x='sample_id', \n",
    "    y='heterozygosity', \n",
    "    color=cohort_col, \n",
    "    color_discrete_map=color_mapping[cohort_col],\n",
    "    template='simple_white', \n",
    "    title=\"Individual sample heterozygosity\", \n",
    "    height=400,\n",
    "    width=900\n",
    ")\n",
    "\n",
    "fig2  = px.histogram(\n",
    "    het_df, \n",
    "    x='heterozygosity', \n",
    "    color=cohort_col, \n",
    "    color_discrete_map=color_mapping[cohort_col],\n",
    "    template='simple_white', \n",
    "    title=\"Histogram of sample heterozygosity\", \n",
    "    height=400,\n",
    "    width=900\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dc96b6",
   "metadata": {},
   "source": [
    "#### Locate heterozygosity outliers\n",
    "\n",
    "We then find samples within each cohort which have a heterozygosity (2.5 * IQR) higher than the 75% quantile, to exclude samples with very high heterozygosity for their cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a32d5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "\n",
    "iqr_multiplier = 2.5 # determines how strict we are in throwing out outliers \n",
    "\n",
    "exclude_samples_heterozygosity = []\n",
    "for coh in het_df[cohort_col].unique():\n",
    "    df = het_df.query(f\"{cohort_col} == @coh\")\n",
    "    hets = df.heterozygosity\n",
    "    \n",
    "    threshold = np.nanquantile(hets, 0.75) + (iqr_multiplier * iqr(hets, nan_policy='omit'))\n",
    "    \n",
    "    if any(hets > threshold):\n",
    "        exclude_samples_heterozygosity.extend(df.query(\"heterozygosity > @threshold\").sample_id.to_list())\n",
    "    \n",
    "    print(f\"For {coh} the heterozygosity threshold is {np.round(threshold, 3)}, out of {len(hets)} samples, {(hets > threshold).sum()} are outliers\")\n",
    "\n",
    "print(f\"\\nRemoving {len(exclude_samples_heterozygosity)} samples in total due to high heterozygosity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc31c28",
   "metadata": {},
   "source": [
    "### Preliminary PCA - remove outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae06650",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import allel\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy import stats\n",
    "import allel\n",
    "    \n",
    "def find_pca_outliers(pca_df, zscore_threshold=3):\n",
    "    \"\"\"\n",
    "    Find outliers in PCA components using Z-score method.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pca_df : pandas DataFrame\n",
    "        DataFrame containing PCA components as columns\n",
    "    zscore_threshold : float\n",
    "        Number of standard deviations for outlier cutoff\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with outlier information:\n",
    "        - max_zscore: Maximum absolute Z-score across all components\n",
    "        - is_outlier: Boolean indicating if point is an outlier\n",
    "        - outlier_components: List of components where point is an outlier\n",
    "    \"\"\"\n",
    "    pca_df = pca_df.filter(like='PC')\n",
    "    # Calculate Z-scores for all components\n",
    "    zscores = pd.DataFrame(\n",
    "        np.abs(stats.zscore(pca_df)),\n",
    "        columns=pca_df.columns,\n",
    "        index=pca_df.index\n",
    "    )\n",
    "    \n",
    "    # Find maximum Z-score for each point\n",
    "    max_zscores = zscores.max(axis=1)\n",
    "    \n",
    "    # Identify which components are outliers for each point\n",
    "    outlier_components = zscores.apply(lambda x: x > zscore_threshold)\n",
    "    outlier_component_lists = outlier_components.apply(\n",
    "        lambda x: list(x.index[x]), axis=1\n",
    "    )\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        'max_zscore': max_zscores,\n",
    "        'is_outlier': max_zscores > zscore_threshold,\n",
    "        'outlier_components': outlier_component_lists\n",
    "    })\n",
    "    \n",
    "    return results.sort_values('max_zscore', ascending=False)\n",
    "\n",
    "vcf_amplicon_path = f\"{wkdir}/results/vcfs/amplicons/{dataset}.annot.vcf\"\n",
    "geno, pos, contigs, metadata, ref, alt, ann = amp.load_vcf(vcf_amplicon_path, metadata, platform=platform)\n",
    "\n",
    "pca_exclude_samples = []\n",
    "for coh in metadata[cohort_col].unique():\n",
    "    pca_df, model = amp.pca(geno, metadata, query=f\"{cohort_col} == '{coh}'\", n_components=3, missing_threshold=0.2)\n",
    "    df_outliers = find_pca_outliers(pca_df.set_index('sample_id'), zscore_threshold=4)\n",
    "\n",
    "    n_samples = df_outliers.shape[0]\n",
    "    n_outliers = df_outliers['is_outlier'].sum()\n",
    "    print(f\"{coh} - Found {n_outliers} PCA outliers in {n_samples} samples using Z-scores\")\n",
    "\n",
    "    outliers = df_outliers[df_outliers['is_outlier']].index.tolist()\n",
    "    pca_exclude_samples.extend(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb559dbd",
   "metadata": {},
   "source": [
    "### Summary of samples to exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed83de9",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "negative_samples = metadata.query(\"sample_id.str.contains('Negative|negative')\", engine='python').sample_id.to_list()\n",
    "diluted_samples = metadata.query(\"sample_id.str.contains('dil')\", engine='python').sample_id.to_list()\n",
    "\n",
    "exclude_samples = np.unique(exclude_samples_depth.to_list() + exclude_samples_heterozygosity + list(exclude_samples_missing_calls) + pca_exclude_samples + negative_samples + diluted_samples)\n",
    "removed_metadata = metadata.query(\"sample_id in @exclude_samples\")[cohort_col].value_counts().to_frame().reset_index()\n",
    "\n",
    "removed_metadata = removed_metadata.set_index(cohort_col).T\n",
    "tot = removed_metadata.sum(axis=1)\n",
    "removed_metadata = removed_metadata.assign(total=tot).T\n",
    "\n",
    "removed_metadata.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b980bc",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "new_metadata = metadata.query(\"sample_id not in @exclude_samples\")\n",
    "new_metadata.to_csv(f\"{wkdir}/results/config/metadata.qcpass.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b96b94",
   "metadata": {},
   "source": [
    "####  Sample QC complete!\n",
    "A new metadata file with low-quality samples removed has been written to results/config/ :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f97a14",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
